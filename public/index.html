<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Parts Manual Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            background: linear-gradient(135deg, #ffffff 0%, #f5f5f5 100%);
            color: #2d2926;
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }

        .container {
            width: 100%;
            max-width: 500px;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 60px;
        }

        /* Email Input Section */
        .email-section {
            width: 100%;
            opacity: 1;
            transition: opacity 0.5s ease, transform 0.5s ease;
        }

        .email-section.hidden {
            opacity: 0;
            transform: translateY(-20px);
            pointer-events: none;
            position: absolute;
        }

        .title {
            font-size: 28px;
            font-weight: 600;
            letter-spacing: -0.5px;
            text-align: center;
            margin-bottom: 8px;
            color: #2d2926;
        }

        .subtitle {
            font-size: 15px;
            color: #979797;
            text-align: center;
            margin-bottom: 40px;
            line-height: 1.5;
        }

        .email-input-wrapper {
            position: relative;
            width: 100%;
        }

        .email-input {
            width: 100%;
            padding: 16px 20px;
            font-size: 16px;
            background: #ffffff;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            color: #2d2926;
            outline: none;
            transition: all 0.3s ease;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }

        .email-input::placeholder {
            color: #979797;
        }

        .email-input:focus {
            border-color: #c8102e;
            box-shadow: 0 0 0 3px rgba(200, 16, 46, 0.1);
        }

        .enter-button {
            margin-top: 20px;
            width: 100%;
            padding: 16px;
            font-size: 16px;
            font-weight: 600;
            background: #c8102e;
            border: none;
            border-radius: 8px;
            color: #ffffff;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(200, 16, 46, 0.2);
        }

        .enter-button:hover {
            background: #aa182c;
            box-shadow: 0 6px 16px rgba(200, 16, 46, 0.3);
            transform: translateY(-2px);
        }

        .enter-button:active {
            transform: translateY(0);
        }

        /* Orb Section */
        .orb-section {
            position: relative;
            opacity: 0;
            transform: scale(0.8);
            transition: opacity 0.5s ease, transform 0.5s ease;
            pointer-events: none;
        }

        .orb-section.active {
            opacity: 1;
            transform: scale(1);
            pointer-events: all;
        }

        .orb-container {
            position: relative;
            width: 200px;
            height: 200px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .orb {
            width: 120px;
            height: 120px;
            background: radial-gradient(circle at 30% 30%, 
                #ffffff,
                #f0f0f0
            );
            border-radius: 50%;
            position: relative;
            box-shadow: 
                0 10px 40px rgba(0, 0, 0, 0.1),
                inset 0 -10px 30px rgba(0, 0, 0, 0.05);
            transition: all 0.3s ease;
            border: 2px solid #e0e0e0;
        }
        
        /* User speaking - blue pulse */
        .orb.user-speaking {
            background: radial-gradient(circle at 30% 30%, 
                #4a90e2,
                #357abd
            );
            border-color: #4a90e2;
            animation: user-pulse 1s ease-in-out infinite;
            box-shadow: 
                0 0 60px rgba(74, 144, 226, 0.4),
                inset 0 0 30px rgba(255, 255, 255, 0.2);
        }
        
        /* Assistant speaking - red pulse */
        .orb.assistant-speaking {
            background: radial-gradient(circle at 30% 30%, 
                #c8102e,
                #aa182c
            );
            border-color: #c8102e;
            animation: assistant-pulse 0.8s ease-in-out infinite;
            box-shadow: 
                0 0 60px rgba(200, 16, 46, 0.4),
                inset 0 0 30px rgba(255, 255, 255, 0.2);
        }
        
        /* Processing - more obvious spinner */
        .orb.processing {
            background: conic-gradient(
                from 0deg,
                #f0f0f0 0deg,
                #c8102e 45deg,
                #f0f0f0 90deg,
                #f0f0f0 270deg,
                #c8102e 315deg,
                #f0f0f0 360deg
            );
            animation: processing-spin 1s linear infinite;
            border-color: #d0d0d0;
            position: relative;
            overflow: hidden;
        }
        
        .orb.processing::before {
            content: '';
            position: absolute;
            top: 10%;
            left: 10%;
            right: 10%;
            bottom: 10%;
            background: #ffffff;
            border-radius: 50%;
            z-index: 1;
        }
        
        .orb.processing::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(90deg, transparent 30%, rgba(255, 255, 255, 0.5) 50%, transparent 70%);
            animation: processing-sweep 1.5s linear infinite;
            border-radius: 50%;
            z-index: 2;
        }
        
        @keyframes processing-spin {
            0% {
                transform: rotate(0deg);
            }
            100% {
                transform: rotate(360deg);
            }
        }
        
        @keyframes processing-sweep {
            0% {
                transform: rotate(0deg);
            }
            100% {
                transform: rotate(360deg);
            }
        }
        
        @keyframes user-pulse {
            0%, 100% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.1);
            }
        }
        
        @keyframes assistant-pulse {
            0%, 100% {
                transform: scale(1);
                filter: brightness(1);
            }
            50% {
                transform: scale(1.15);
                filter: brightness(1.2);
            }
        }

        .orb::before {
            content: '';
            position: absolute;
            top: -40%;
            left: -40%;
            right: -40%;
            bottom: -40%;
            border-radius: 50%;
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .orb.user-speaking::before {
            background: radial-gradient(circle at center, 
                transparent 40%,
                rgba(74, 144, 226, 0.2) 60%,
                transparent 70%
            );
            animation: pulse-ring 1.5s infinite ease-out;
            opacity: 1;
        }
        
        .orb.assistant-speaking::before {
            background: radial-gradient(circle at center, 
                transparent 40%,
                rgba(200, 16, 46, 0.2) 60%,
                transparent 70%
            );
            animation: pulse-ring 1.2s infinite ease-out;
            opacity: 1;
        }

        .orb::after {
            content: '';
            position: absolute;
            top: -20%;
            left: -20%;
            right: -20%;
            bottom: -20%;
            border-radius: 50%;
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        .orb.user-speaking::after {
            background: radial-gradient(circle at center, 
                transparent 50%,
                rgba(74, 144, 226, 0.15) 70%,
                transparent 80%
            );
            animation: pulse-ring-2 1.8s infinite ease-out 0.3s;
            opacity: 1;
        }
        
        .orb.assistant-speaking::after {
            background: radial-gradient(circle at center, 
                transparent 50%,
                rgba(200, 16, 46, 0.15) 70%,
                transparent 80%
            );
            animation: pulse-ring-2 1.5s infinite ease-out 0.2s;
            opacity: 1;
        }

        @keyframes pulse-ring {
            0% {
                transform: scale(0.8);
                opacity: 1;
            }
            100% {
                transform: scale(1.4);
                opacity: 0;
            }
        }

        @keyframes pulse-ring-2 {
            0% {
                transform: scale(0.9);
                opacity: 0.8;
            }
            100% {
                transform: scale(1.3);
                opacity: 0;
            }
        }


        /* Status Text */
        .status {
            margin-top: 30px;
            font-size: 14px;
            color: #979797;
            text-align: center;
            min-height: 20px;
            font-weight: 500;
        }

        .status.listening {
            color: #2d2926;
        }
        
        .status.user-speaking {
            color: #4a90e2;
        }
        
        .status.assistant-speaking {
            color: #c8102e;
        }
        
        .status.processing {
            color: #979797;
            font-style: italic;
        }

        /* Error Message */
        .error {
            color: #c8102e;
            font-size: 13px;
            margin-top: 8px;
            text-align: center;
            font-weight: 500;
        }

        /* Loading spinner */
        .spinner {
            width: 20px;
            height: 20px;
            border: 2px solid rgba(255, 255, 255, 0.1);
            border-top-color: rgba(255, 255, 255, 0.6);
            border-radius: 50%;
            animation: spin 0.8s linear infinite;
            margin: 0 auto;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        /* End Session Button */
        .end-button {
            position: absolute;
            bottom: 40px;
            left: 50%;
            transform: translateX(-50%);
            padding: 12px 32px;
            font-size: 14px;
            font-weight: 500;
            background: #ffffff;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            color: #979797;
            cursor: pointer;
            transition: all 0.3s ease;
            opacity: 0;
            pointer-events: none;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }

        .end-button.visible {
            opacity: 1;
            pointer-events: all;
        }

        .end-button:hover {
            border-color: #c8102e;
            color: #c8102e;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Email Input Section -->
        <div class="email-section" id="emailSection">
            <h1 class="title">Parts Manual Finder</h1>
            <p class="subtitle">Enter your email to receive equipment manuals directly</p>
            <div class="email-input-wrapper">
                <input 
                    type="email" 
                    id="emailInput" 
                    class="email-input" 
                    placeholder="your@email.com"
                    autocomplete="email"
                    autofocus
                >
                <div class="error" id="errorMessage"></div>
            </div>
            <button id="enterButton" class="enter-button">Start Session</button>
        </div>

        <!-- Orb Section -->
        <div class="orb-section" id="orbSection">
            <div class="orb-container">
                <div class="orb" id="orb"></div>
            </div>
            <div class="status" id="status">Connecting...</div>
        </div>
    </div>

    <button id="endButton" class="end-button">End Session</button>

    <script>
        // Configuration - use relative URLs to work with the same domain
        const WS_URL = `wss://${window.location.host}/api/v1/voice/realtime`;
        const API_URL = `https://${window.location.host}`;
        
        // DOM Elements
        const emailSection = document.getElementById('emailSection');
        const emailInput = document.getElementById('emailInput');
        const enterButton = document.getElementById('enterButton');
        const orbSection = document.getElementById('orbSection');
        const orb = document.getElementById('orb');
        const status = document.getElementById('status');
        const errorMessage = document.getElementById('errorMessage');
        const endButton = document.getElementById('endButton');

        // State
        let ws = null;
        let audioStream = null;
        let audioContext = null;
        let source = null;
        let processor = null;
        let playbackContext = null;
        let userEmail = '';
        let sessionActive = false;
        let isStreaming = false;
        let isPlaying = false;
        let audioQueue = [];
        let isUserSpeaking = false;
        let userSpeakingTimeout = null;
        let silenceThreshold = 0.015; // Balanced sensitivity for voice detection
        let currentPlaybackSource = null;
        let gainNode = null;
        let isFadingOut = false;
        let inputBufferDelay = null;
        let audioChunkBuffer = [];
        let audioBufferTimeout = null;
        let isProcessing = false;

        // Email validation
        function validateEmail(email) {
            const re = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
            return re.test(email);
        }

        // Handle email submission
        function handleEmailSubmit() {
            const email = emailInput.value.trim();
            
            if (!validateEmail(email)) {
                errorMessage.textContent = 'Please enter a valid email address';
                emailInput.focus();
                return;
            }

            userEmail = email;
            errorMessage.textContent = '';
            startSession();
        }

        // Start voice session
        async function startSession() {
            try {
                // Hide email section, show orb
                emailSection.classList.add('hidden');
                orbSection.classList.add('active');
                status.textContent = 'Connecting...';

                console.log('Getting access token from:', `${API_URL}/api/v1/voice/token`);

                // Get access token first
                const tokenResponse = await fetch(`${API_URL}/api/v1/voice/token`, {
                    method: 'GET',
                    headers: {
                        'Content-Type': 'application/json'
                    }
                });

                console.log('Token response status:', tokenResponse.status);

                if (!tokenResponse.ok) {
                    const errorText = await tokenResponse.text();
                    console.error('Token error response:', errorText);
                    throw new Error(`Failed to get access token: ${tokenResponse.status}`);
                }

                const response = await tokenResponse.json();
                console.log('Token response received:', response);
                
                // Extract token from the wrapped response
                const token = response.data?.token || response.token;
                const sessionId = response.data?.sessionId || response.sessionId || 'session-' + Date.now();
                
                if (!token) {
                    throw new Error('No token received from server');
                }

                console.log('Connecting WebSocket with token:', token.substring(0, 20) + '...');

                // Connect WebSocket with token and user email
                const wsUrl = response.data.url.replace('http://', 'ws://').replace('https://', 'wss://');
                ws = new WebSocket(`${wsUrl}?token=${token}&email=${encodeURIComponent(userEmail)}`);
                
                ws.onopen = async () => {
                    console.log('WebSocket connected');
                    sessionActive = true;
                    
                    // Ensure orb starts in neutral state
                    orb.classList.remove('assistant-speaking', 'user-speaking', 'processing');
                    status.classList.remove('assistant-speaking', 'user-speaking', 'processing');
                    orb.style.transform = 'scale(1)';
                    orb.style.boxShadow = '';
                    
                    // Start audio streaming immediately after connection
                    await startAudioStream();
                    
                    // Show end button
                    endButton.classList.add('visible');
                    status.textContent = 'Ready to help you find manuals';
                    status.classList.add('listening');
                };
                
                ws.onmessage = (event) => {
                    const message = JSON.parse(event.data);
                    handleMessage(message);
                };
                
                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    showError('Connection error occurred');
                };
                
                ws.onclose = () => {
                    console.log('WebSocket closed');
                    if (sessionActive) {
                        endSession();
                    }
                };

            } catch (error) {
                console.error('Failed to start session:', error);
                status.textContent = 'Connection failed. Please try again.';
                orbSection.classList.remove('active');
                emailSection.classList.remove('hidden');
                errorMessage.textContent = 'Failed to start session. Please try again.';
            }
        }

        function showError(message) {
            errorMessage.textContent = message;
            setTimeout(() => {
                errorMessage.textContent = '';
            }, 5000);
        }

        // Handle incoming messages
        function handleMessage(message) {
            switch (message.type) {
                case 'session.created':
                    console.log('Session created:', message);
                    break;
                    
                case 'response.audio.delta':
                    const audio = message.delta || message.data?.delta || message.audio;
                    if (audio) {
                        playAudioChunk(audio);
                        if (!orb.classList.contains('assistant-speaking')) {
                            // Clear processing state
                            isProcessing = false;
                            // Remove all other states
                            orb.classList.remove('user-speaking', 'processing');
                            status.classList.remove('user-speaking', 'processing');
                            // Add assistant speaking classes
                            orb.classList.add('assistant-speaking');
                            status.classList.add('assistant-speaking');
                            status.textContent = 'Assistant is responding...';
                        }
                    }
                    break;
                    
                case 'response.audio.done':
                    // Audio chunk complete, more may be coming
                    break;
                    
                case 'response.done':
                    // Full response complete - but audio might still be playing
                    // Don't remove animation immediately, let playback finish
                    console.log('Response done, audio queue length:', audioQueue.length);
                    break;
                    
                case 'input_audio_transcription.completed':
                    console.log('User said:', message.data?.transcript);
                    break;
                    
                case 'error':
                    console.error('Server error:', message);
                    showError(message.error || 'An error occurred');
                    break;
            }
        }

        // Play audio chunk with buffering
        async function playAudioChunk(base64Audio) {
            // Add to buffer for smoother playback
            audioChunkBuffer.push(base64Audio);
            
            // Clear existing timeout
            if (audioBufferTimeout) {
                clearTimeout(audioBufferTimeout);
            }
            
            // Wait a bit to collect more chunks for smoother playback
            audioBufferTimeout = setTimeout(() => {
                while (audioChunkBuffer.length > 0) {
                    audioQueue.push(audioChunkBuffer.shift());
                }
                if (!isPlaying && !isFadingOut) {
                    playNextChunk();
                }
            }, 50); // 50ms buffer
        }
        
        // Stop audio playback with fade out
        function stopAudioPlayback() {
            if (!isPlaying || !gainNode || !playbackContext) return;
            
            isFadingOut = true;
            const currentTime = playbackContext.currentTime;
            
            // Fade out over 200ms
            gainNode.gain.cancelScheduledValues(currentTime);
            gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
            gainNode.gain.linearRampToValueAtTime(0, currentTime + 0.2);
            
            // Stop after fade out
            setTimeout(() => {
                if (currentPlaybackSource) {
                    try {
                        currentPlaybackSource.stop();
                    } catch (e) {
                        // Already stopped
                    }
                    currentPlaybackSource = null;
                }
                
                // Clear audio queue
                audioQueue = [];
                audioChunkBuffer = [];
                isPlaying = false;
                isFadingOut = false;
                
                // Cancel any animation frames
                if (animationFrame) {
                    cancelAnimationFrame(animationFrame);
                    animationFrame = null;
                }
                
                // Reset gain for next playback
                if (gainNode) {
                    gainNode.gain.value = 0;
                }
                
                // Remove assistant visuals
                orb.classList.remove('assistant-speaking');
                status.classList.remove('assistant-speaking');
                orb.style.transform = 'scale(1)';
                orb.style.boxShadow = '';
            }, 200);
        }

        async function playNextChunk() {
            if (audioQueue.length === 0 || isFadingOut) {
                isPlaying = false;
                
                // No more audio to play, remove assistant speaking animation
                setTimeout(() => {
                    if (!isPlaying && !isUserSpeaking && !isProcessing) {
                        orb.classList.remove('assistant-speaking', 'processing');
                        status.classList.remove('assistant-speaking', 'processing');
                        status.classList.add('listening');
                        status.textContent = 'Listening for your question...';
                    }
                }, 200);
                return;
            }

            isPlaying = true;

            try {
                if (!playbackContext) {
                    playbackContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                    gainNode = playbackContext.createGain();
                    gainNode.connect(playbackContext.destination);
                    gainNode.gain.value = 0; // Start at 0 for fade in
                }

                const base64Audio = audioQueue.shift();
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Convert PCM16 to Float32
                const pcm16 = new Int16Array(bytes.buffer);
                const float32 = new Float32Array(pcm16.length);
                
                for (let i = 0; i < pcm16.length; i++) {
                    float32[i] = pcm16[i] / 32768.0;
                }

                // Apply smoothing window to reduce clicks
                const windowSize = 128;
                for (let i = 0; i < windowSize && i < float32.length; i++) {
                    float32[i] *= i / windowSize; // Fade in
                }
                for (let i = float32.length - windowSize; i < float32.length && i >= 0; i++) {
                    float32[i] *= (float32.length - i) / windowSize; // Fade out
                }

                // Create and play buffer
                const audioBuffer = playbackContext.createBuffer(1, float32.length, 24000);
                audioBuffer.getChannelData(0).set(float32);

                const source = playbackContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(gainNode);
                
                currentPlaybackSource = source;
                
                // Smooth fade in
                const currentTime = playbackContext.currentTime;
                if (!isFadingOut) {
                    gainNode.gain.cancelScheduledValues(currentTime);
                    gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
                    gainNode.gain.linearRampToValueAtTime(1.0, currentTime + 0.05); // 50ms fade in
                }
                
                source.onended = () => {
                    currentPlaybackSource = null;
                    if (!isFadingOut) {
                        playNextChunk();
                    }
                };
                
                source.start();

            } catch (error) {
                console.error('Audio playback error:', error);
                isPlaying = false;
            }
        }

        // Start audio streaming
        async function startAudioStream() {
            try {
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 24000,
                        sampleSize: 16,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                source = audioContext.createMediaStreamSource(audioStream);
                processor = audioContext.createScriptProcessor(2048, 1, 1);

                source.connect(processor);
                processor.connect(audioContext.destination);

                processor.onaudioprocess = (e) => {
                    if (isStreaming && ws && ws.readyState === WebSocket.OPEN) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        
                        // Detect if user is speaking
                        const hasSound = detectUserSpeaking(inputData);
                        const wasUserSpeaking = isUserSpeaking;
                        updateUserSpeakingState(hasSound);
                        
                        // If user just started speaking while assistant is playing, interrupt
                        if (!wasUserSpeaking && isUserSpeaking && isPlaying) {
                            console.log('User interrupting assistant');
                            
                            // Stop playback FIRST
                            stopAudioPlayback();
                            isPlaying = false; // Ensure flag is set
                            
                            // Then update visual
                            isProcessing = false;
                            // Force remove all classes first
                            orb.className = 'orb';
                            status.className = 'status';
                            
                            // Then add user speaking classes
                            setTimeout(() => {
                                orb.classList.add('user-speaking');
                                status.classList.add('user-speaking');
                                status.textContent = 'Listening to you...';
                                updateOrbScale('user', currentUserAudioLevel);
                            }, 10);
                            
                            // Send interruption signal to server
                            ws.send(JSON.stringify({ type: 'response.cancel' }));
                            
                            // Clear input buffer briefly to avoid echo
                            if (inputBufferDelay) {
                                clearTimeout(inputBufferDelay);
                            }
                            inputBufferDelay = setTimeout(() => {
                                inputBufferDelay = null;
                            }, 300); // 300ms delay after interruption
                            return;
                        }
                        
                        // Don't send audio during the delay period after interruption
                        if (inputBufferDelay) {
                            return;
                        }
                        
                        // Convert and send audio
                        const pcm16 = convertFloat32ToPCM16(inputData);
                        const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                        
                        ws.send(JSON.stringify({
                            type: 'input_audio_buffer.append',
                            audio: base64
                        }));
                    }
                };

                isStreaming = true;
                console.log('Audio streaming started');
                
            } catch (error) {
                console.error('Failed to start audio stream:', error);
                showError('Failed to access microphone. Please check permissions.');
            }
        }

        // Convert Float32 audio to PCM16
        function convertFloat32ToPCM16(float32Array) {
            const pcm16 = new Int16Array(float32Array.length);
            for (let i = 0; i < float32Array.length; i++) {
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return pcm16;
        }
        
        // Detect if user is speaking with adaptive threshold
        function detectUserSpeaking(audioData) {
            let sum = 0;
            let maxAmplitude = 0;
            
            for (let i = 0; i < audioData.length; i++) {
                sum += audioData[i] * audioData[i];
                maxAmplitude = Math.max(maxAmplitude, Math.abs(audioData[i]));
            }
            
            const rms = Math.sqrt(sum / audioData.length);
            
            // Use combination of RMS and peak detection for better accuracy
            const isLoudEnough = rms > silenceThreshold || maxAmplitude > 0.1;
            
            // Additional frequency analysis for voice detection
            if (isLoudEnough && audioData.length > 0) {
                // Simple zero-crossing rate for basic voice detection
                let zeroCrossings = 0;
                for (let i = 1; i < audioData.length; i++) {
                    if ((audioData[i] >= 0) !== (audioData[i - 1] >= 0)) {
                        zeroCrossings++;
                    }
                }
                const zcr = zeroCrossings / audioData.length;
                
                // Human voice typically has ZCR between 0.02 and 0.2
                // Be more lenient to avoid cutting off
                return isLoudEnough && zcr > 0.005 && zcr < 0.4;
            }
            
            return false;
        }
        
        // Update user speaking state
        function updateUserSpeakingState(hasSound) {
            if (hasSound) {
                // Clear any existing timeout
                if (userSpeakingTimeout) {
                    clearTimeout(userSpeakingTimeout);
                    userSpeakingTimeout = null;
                }
                
                // User is speaking - only show animation if not already showing
                if (!isUserSpeaking) {
                    isUserSpeaking = true;
                    isProcessing = false; // Clear processing when user speaks
                    // Only change visual if assistant is not speaking
                    if (!isPlaying) {
                        // Remove all other states
                        orb.classList.remove('assistant-speaking', 'processing');
                        status.classList.remove('assistant-speaking', 'processing');
                        // Add user speaking classes
                        orb.classList.add('user-speaking');
                        status.classList.add('user-speaking');
                        status.textContent = 'Listening to you...';
                    }
                }
            } else if (isUserSpeaking && !hasSound) {
                // User stopped speaking - add delay before removing visual
                if (!userSpeakingTimeout) {
                    userSpeakingTimeout = setTimeout(() => {
                        isUserSpeaking = false;
                        
                        // Only remove animation if assistant is not playing
                        if (!isPlaying) {
                            // Switch to processing state
                            isProcessing = true;
                            orb.classList.remove('user-speaking');
                            status.classList.remove('user-speaking');
                            orb.style.transform = 'scale(1)'; // Reset scale
                            orb.style.boxShadow = ''; // Reset glow
                            orb.classList.add('processing');
                            status.classList.add('processing');
                            status.textContent = 'Processing your request...';
                        }
                        
                        // Send commit audio buffer after user stops speaking
                        if (ws && ws.readyState === WebSocket.OPEN && !isPlaying) {
                            setTimeout(() => {
                                ws.send(JSON.stringify({ type: 'input_audio_buffer.commit' }));
                            }, 100);
                        }
                        
                        userSpeakingTimeout = null;
                    }, 600); // Reduced to 600ms for more responsive feel
                }
            }
        }

        // Send text message
        function sendTextMessage(text) {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                    type: 'conversation.item.create',
                    item: {
                        type: 'message',
                        role: 'user',
                        content: [{
                            type: 'input_text',
                            text: text
                        }]
                    }
                }));
                
                // Trigger response
                ws.send(JSON.stringify({ type: 'response.create' }));
            }
        }

        // Stop audio streaming
        function stopAudioStream() {
            isStreaming = false;
            
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            
            if (source) {
                source.disconnect();
                source = null;
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (playbackContext) {
                playbackContext.close();
                playbackContext = null;
            }
        }

        // End session
        function endSession() {
            sessionActive = false;
            
            // Stop audio playback immediately
            stopAudioPlayback();
            
            // Stop audio streaming
            stopAudioStream();

            // Close WebSocket
            if (ws) {
                ws.close();
                ws = null;
            }

            // Clear audio queue and buffers
            audioQueue = [];
            audioChunkBuffer = [];
            isPlaying = false;
            isFadingOut = false;

            // Reset UI
            orb.classList.remove('user-speaking', 'assistant-speaking', 'processing');
            status.classList.remove('user-speaking', 'assistant-speaking', 'processing');
            orb.style.transform = 'scale(1)'; // Reset scale
            orb.style.boxShadow = ''; // Reset glow
            orbSection.classList.remove('active');
            emailSection.classList.remove('hidden');
            endButton.classList.remove('visible');
            status.classList.remove('listening');
            emailInput.value = '';
            userEmail = '';
            isProcessing = false;
            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
                animationFrame = null;
            }
        }

        // Event listeners
        emailInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                handleEmailSubmit();
            }
        });

        enterButton.addEventListener('click', handleEmailSubmit);
        endButton.addEventListener('click', endSession);

        // Auto-focus email input
        emailInput.focus();
    </script>
</body>
</html>